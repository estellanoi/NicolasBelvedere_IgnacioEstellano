##Ignacio Estellano y Nicolas Belvedere

# Notebook overview

The objective of this notebook is to offer a first approximation at Image Classification problems.

For this, we will be using a very popular library `PyTorch` and a DataSet of fruits and vegetables.



---


❗ **Before running the notebook in colab, go to the top menu: `Runtime` > `Change runtime type` > `Hardware accelerator` and select the option "T4 GPU" to ensure faster execution.**

!pip install -q eccd_datasets

import io
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import requests
import torch
import torchvision.transforms.v2 as transforms

from eccd_datasets import load_images
from PIL import Image
from torchvision import models

torch.manual_seed(42)

# Download the original lables used when training a resnet

resnet_labels = {
    int(index): label
    for index, (id, label) in requests.get(
        "https://files.fast.ai/models/imagenet_class_index.json"
    )
    .json()
    .items()
}
resnet_labels[10]

# Exploring the dataset

First, we invite you to go to the dataset folder and explore the content and structure of the project.

The dataset used in this notebook consists on a subset from the dataset located [here](https://github.com/marcusklasson/GroceryStoreDataset)

Once that is done, we can start looking at what is included in the dataset

df_images = load_images()
df_images.head()


df_images['coarse_cat'].value_counts()

print(df_images.shape)


### Looking at the images

We can use the `PIL` library to look at the images

def load_image_data(image_data):
    return Image.open(io.BytesIO(image_data))

image = load_image_data(df_images.iloc[0]["image_data"])
image

### Images as matrices

We can also look  at the matrix representation of each image using numpy

I = np.array(image)
print("Image shape", I.shape)
print(f"Image range in each coordinate: [{I.min()}, {I.max()}]")

And we can modify the image manually by changing the values of the matrix

new_I = I.copy()
new_I[:, :, 0] = 0 # Killing the red channel

plt.imshow(new_I.astype(int))

# PyTorch Transformations

The same way we normalize tabular data with Standard and MinMax scalers, we need to normalize image data.

We will proceed to explore some of the most used transformations

## Resizing

resize_image = transforms.Resize((100, 100))

resized_image = resize_image(image)

plt.imshow(resized_image)
plt.title(f"New shape: {np.array(resized_image).shape}")

## Center Crop

Implement a transformation for croping and centering (hint: there is a transformation that does that)

type(image)

def center_crop_transformation(image, size: int) -> np.array:

    # Apply center crop transformation
    crop_transform = transforms.CenterCrop(size)
    cropped_image = crop_transform(image)

    # Convert to numpy array if needed
    return np.array(cropped_image)


answer_center_crop = center_crop_transformation(image, 150)
plt.imshow(answer_center_crop)

assert np.array(answer_center_crop).shape == (150, 150, 3)

## RandomResizedCrop

print("Image original size: ", np.array(image).shape)
fig, ax = plt.subplots(1, 6, figsize=(20, 4))
for i, size in enumerate([50, 100, 150, 200, 300, 500]):

    transformation = transforms.RandomResizedCrop(size)

    crp_img = transformation(image)
    ax[i].imshow(crp_img)
    ax[i].set_title(np.array(crp_img).shape)

## Random Horizontal Flip

transformation = transforms.RandomHorizontalFlip()

maybe_flipped = [transformation(image) for _ in range(5)]

plt.imshow(np.hstack([np.array(img) for img in maybe_flipped]))

## Normalization

The same way we normalize columns for tabular data, here we normalize each image according to the mean and standard deviation of each colour channel.

two_images = [
    load_image_data(row["image_data"]) for _, row in df_images.iloc[:2].iterrows()
]

two_image_dataset = np.array([np.array(img) for img in two_images])
two_image_dataset.shape

plt.imshow(np.hstack([np.array(img) for img in two_images]))

two_image_dataset.shape

np.mean(two_image_dataset, axis=(0, 1, 2))

transformation = transforms.Compose(
    [
        transforms.ToImage(),
        transforms.ToDtype(torch.float32, scale=True),
        transforms.Normalize(
            np.mean(two_image_dataset, axis=(0, 1, 2)),
            np.std(two_image_dataset, axis=(0, 1, 2)),
        ),
    ]
)

transformed_two_image_dataset = [transformation(img) for img in two_image_dataset]

transformed_two_image_dataset[0]

# Using ImageNet

Since training a large neural network requires lots of data and computing power, often we download a pre-trained neural network, which we can later fine-tune.

Here, we will download an ImageNet network.

Remember that since the network is already trained with a specific dataset, when evaluating new images, we need transform them using the same transformations used for training. In particular, that includes using the same normalizations.

resnet = models.resnet18(pretrained=True)
# resnet = models.resnet34(pretrained=True)
# resnet = models.resnet50(pretrained=True)
# resnet = models.resnet101(pretrained=True)
# resnet = models.resnet152(pretrained=True)
resnet.eval()

resnet

We load a maping from resnet integer labels to the actual categories

def predict_using_resnet(image):
    """
    Esta función utiliza el modelo ResNet para predecir la categoría de una imagen.
    Aplica las transformaciones necesarias, carga el modelo ResNet y devuelve la clase de mayor probabilidad.
    """

    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    input_tensor = preprocess(image)
    input_batch = input_tensor.unsqueeze(0)


    model = models.resnet18(weights="IMAGENET1K_V1")
    model.eval()


    if torch.cuda.is_available():
        input_batch = input_batch.to('cuda')
        model.to('cuda')


    with torch.no_grad():
        output = model(input_batch)


    probabilities = torch.nn.functional.softmax(output[0], dim=0)


    url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
    urllib.request.urlretrieve(url, "imagenet_classes.txt")


    with open("imagenet_classes.txt", "r") as f:
        categories = [s.strip() for s in f.readlines()]


    max_prob, max_catid = torch.max(probabilities, 0)
    predicted_class = categories[max_catid]

    print(f"Clase predicha: {predicted_class}, Probabilidad: {max_prob.item():.4f}")

    return predicted_class



img1 = (
    load_image_data(
        df_images[
            df_images["coarse_cat"] == "Apple"
        ]
        .iloc[0]
        ["image_data"]
    )
)
img1

img2 = (
    load_image_data(
        df_images[
            df_images["coarse_cat"] == "Orange"
        ]
        .iloc[0]
        ["image_data"]
    )
)
img2

img3 = (
    load_image_data(
        df_images[
            df_images["coarse_cat"] == "Pear"
        ]
        .iloc[0]
        ["image_data"]
    )
)
img3

pred1 = predict_using_resnet(img1)
print(pred1)

assert pred1 == "lemon"

pred2 = predict_using_resnet(img2)
print(pred2)

pred3 = predict_using_resnet(img3)
print(pred3)
